{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee337c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "!pip install clinicadl==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae69e64",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "# Launch a random search\n",
    "\n",
    "The previous section focused on a way to debug non-automated architecture\n",
    "search. However, if you have enough computational power, you may want to\n",
    "launch an automated architecture search to save your time. This is the point\n",
    "of the random search method of ClinicaDL.\n",
    "\n",
    "```{warning}\n",
    "**Non-optimal result:**\n",
    "    A random search may allow to find a better performing network, however\n",
    "    there is no guarantee that this is the best performing network.\n",
    "```\n",
    "\n",
    "This notebook relies on the synthetic data generated in the previous notebook.\n",
    "If you did not run it, uncomment the following cell to generate the\n",
    "corresponding dataset. If you want to generate a bigger synthetic CAPS, \n",
    "please check this [notebook](./generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -k https://aramislab.paris.inria.fr/files/data/handbook_2023/data_oasis/CAPS_extracted.tar.gz -o oasisCaps.tar.gz\n",
    "!tar xf oasisCaps.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ce69e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!clinicadl generate trivial data_oasis/CAPS_example data/synthetic --n_subjects 4 --preprocessing t1-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf8332",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Define the hyperparameter space\n",
    "\n",
    "A random search is performed according to hyperparameters of the network that\n",
    "are sampled from a pre-defined space.  For example, you may want your random\n",
    "network to have maximum 3 fully-convolutional layers as you don't have enough\n",
    "memory to tackle more.\n",
    "\n",
    "This hyperparameter space is defined in a TOML file that must be written in\n",
    "your random search directory: `random_search.toml`.\n",
    "\n",
    "The following function `generate_dict` generates a dictionary that will be\n",
    "used to  `random_search.toml` for this tutorial. To accelerate the training\n",
    "task we will use a single CNN on the default region of interest, the\n",
    "hippocampi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039d0c2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def generate_dict(gpu_avail, caps_dir, tsv_path, preprocessing_json):\n",
    "    return {\n",
    "        \"Random_Search\":{\n",
    "            \"caps_directory\": caps_dir,\n",
    "            \"tsv_path\": tsv_path,\n",
    "            \"diagnoses\": ['AD', 'CN'],\n",
    "            \"preprocessing_json\": preprocessing_json,\n",
    "            \"network_task\": \"classification\",\n",
    "            \"n_convblocks\": [1, 5],   # Number of convolutional blocks\n",
    "            \"first_conv_width\": [8, 16, 32, 64],  # Number of channels in the first convolutional block\n",
    "            \"n_fcblocks\": [1, 3]\n",
    "            },                # Number of (fully-connected + activation) layers\n",
    "        \"Computational\":{\n",
    "            \"gpu\": gpu_avail\n",
    "            },\n",
    "        \"Optimization\":{\n",
    "            \"epochs\": 30,\n",
    "            \"learning_rate\": [4, 6]     # Threshold at which a region is selected if its corresponding balanced accuracy is higher.\n",
    "            },         \n",
    "        \"Cross_validation\":{\n",
    "            \"n_splits\":3\n",
    "            }                            \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d631ac6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In this default dictionary we set all the arguments that are mandatory for the\n",
    "random search. Hyperparameters for which a space is not defined will\n",
    "automatically have their default value in all cases.\n",
    "\n",
    "Hyperparameters can be sampled in 4 different ways:\n",
    "- choice samples one element from a list (ex: `first_conv_width`),\n",
    "- uniform draws samples from a uniform distribution over the interval [min,\n",
    "max] (ex: `selection_threshold`),\n",
    "- exponent draws x from a uniform distribution over the interval [min, max]\n",
    "and return $10^{-x}$ (ex: `learning_rate`),\n",
    "- randint returns an integer in [min, max] (ex: `n_conv_blocks`).\n",
    "\n",
    "The values of some variables are also fixed, meaning that they cannot be\n",
    "sampled and that they should be given a unique value.\n",
    "\n",
    "The values of the variables that can be set in random_search.toml correspond\n",
    "to the options of the train function.  Values of the Computational resources\n",
    "section can also be redefined using the command line. Some variables were also\n",
    "added to sample the architecture of the network.\n",
    "\n",
    "In the default dictionary, the learning rate will be sampled between $10^{-4}$\n",
    "and $10^{-6}$.\n",
    "\n",
    "This dictionary is written as a TOML  file in the `launch_dir` of the\n",
    "random-search.\n",
    "You can define differently other hyperparameters by looking at the\n",
    "[documentation](https://clinicadl.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa90d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "\n",
    "mode = \"image\"\n",
    "caps_dir = \"data/synthetic\"\n",
    "tsv_path = \"data/split/3_fold\"\n",
    "preprocessing_json = \"extract_T1linear_image.json\"\n",
    "\n",
    "os.makedirs(\"random_search\", exist_ok=True)\n",
    "default_dict = generate_dict(gpu_avail, caps_dir, tsv_path, preprocessing_json)\n",
    "# Add some changes here\n",
    "import toml\n",
    "\n",
    "toml_string = toml.dumps(default_dict)  # Output to a string\n",
    "\n",
    "output_file_name = \"random_search/random_search.toml\"\n",
    "with open(output_file_name, \"w\") as toml_file:\n",
    "    toml.dump(default_dict, toml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fe1a2",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "You need to execute the [`clinicadl tsvtool\n",
    "getlabels`](TSVTools.md#getlabels---extract-labels-specific-to-alzheimers-disease)\n",
    "and [`clinicadl tsvtool\n",
    "{split|kfold}`](TSVTools.md#split---single-split-observing-similar-age-and-sex-distributions)\n",
    "commands prior to running this task to have the correct TSV file organization.\n",
    "Moreover, there should be a CAPS, obtained running the `t1-linear` pipeline of\n",
    "ClinicaDL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2baff",
   "metadata": {},
   "source": [
    "# Running the task\n",
    "\n",
    "This task can be run with the following command line:\n",
    "```Text\n",
    "clinicadl random-search [OPTIONS] LAUNCH_DIRECTORY NAME\n",
    "```\n",
    "where:\n",
    "\n",
    "- `launch_directory` (Path) is the parent directory of output folder\n",
    "containing the file `random_search.toml`.\n",
    "- `name` (str) is the name of the output folder containing the experiment.\n",
    "\n",
    "### Content of `random_search.toml`\n",
    "\n",
    "`random_search.toml` must be present in `launch_dir` before running the\n",
    "command. \n",
    "\n",
    "Mandatory variables:\n",
    "\n",
    "- `network_task` (str) is the task learnt by the network. \n",
    "  Must be chosen between `classification` and `regression`\n",
    "  (random sampling for`reconstruction` is not implemented yet).\n",
    "  Sampling function: `fixed`.\n",
    "- `caps_directory` (str) is the input folder containing the neuroimaging data in a [CAPS](https://aramislab.paris.inria.fr/clinica/docs/public/latest/CAPS/Introduction/) hierarchy.\n",
    "Sampling function: `fixed`.\n",
    "- `preprocessing_json` (str) corresponds to the JSON file produced by\n",
    "`clinicadl extract` used for the search.  Sampling function: `fixed`.\n",
    "- `tsv_path` (str) is the input folder of a TSV file tree generated by\n",
    "`clinicadl tsvtool {split|kfold}`.  Sampling function: `fixed`.\n",
    "- `diagnoses` (list of str) is the list of the labels that will be used for\n",
    "training.  Sampling function: `fixed`.\n",
    "- `epochs` (int) is the [maximum number of\n",
    "epochs](Train/Details.md#stopping-criterion).  Sampling function: `fixed`.\n",
    "- `n_convblocks` (int) is the number of convolutional blocks in CNN.  Sampling\n",
    "function: `randint`.\n",
    "- `first_conv_width` (int) is the number of kernels in the first convolutional\n",
    "layer.  Sampling function: `choice`.\n",
    "- `n_fcblocks` (int) is the number of fully-connected layers at the end of the\n",
    "CNN.  Sampling function: `randint`.\n",
    "\n",
    "## Train & evaluate a random network\n",
    "Based on the hyperparameter space described in `random_search.json`, you will\n",
    "now be able to train a random network. To do so the following command can be\n",
    "run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da949158",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!clinicadl random-search random_search maps_random_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a774f7a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "A new folder `test` has been created in `launch_dir`. As for any network\n",
    "trained with ClinicaDL it is possible to evaluate its performance on a test\n",
    "set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880ee91",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Evaluate the network performance on the 2 test images\n",
    "!clinicadl predict random_search/maps_random_search test --participant_tsv data/split/test.tsv --caps_directory data/synthetic --selection_metrics \"loss\" --no-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf67c5b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "split = 0\n",
    "\n",
    "predictions = pd.read_csv(\"./random_search/maps_random_search/split-%i/best-loss/test_image_level_prediction.tsv\" % split, sep=\"\\t\")\n",
    "display(predictions)\n",
    "\n",
    "\n",
    "metrics = pd.read_csv(\"./random_search/maps_random_search/split-%i/best-loss/test_image_level_metrics.tsv\" % split, sep=\"\\t\")\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14a9cf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Analysis of the random network\n",
    "\n",
    "The architecture of the network can be retrieved from the `maps.json`\n",
    "file in the folder corresponding to a random job.\n",
    "\n",
    "The architecture can be fully retrieved with 4 keys:\n",
    "- `convolutions` is a dictionary describing each convolutional block,\n",
    "- `network_normalization` is the type of normalization layer used in\n",
    "convolutional blocks,\n",
    "- `n_fcblocks` is the number of fully-connected layers,\n",
    "- `dropout` is the dropout rate applied at the dropout layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c99a6",
   "metadata": {},
   "source": [
    "One convolutional block is described by the following values:\n",
    "- `in_channels` is the number of channels of the input (if set to null\n",
    "corresponds to the number of channels of the input data),\n",
    "- `out_channels` is the number of channels in the output of the convolutional\n",
    "block. It corresponds to 2 * `in_channels` except for the first channel chosen\n",
    "from `first_conv_width`, and if it becomes greater than `channels_limit`.\n",
    "- `n_conv` corresponds to the number of convolutions in the convolutional\n",
    "block,\n",
    "- `d_reduction` is the dimension reduction applied in the block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b02284",
   "metadata": {},
   "source": [
    "### Convolutional block - example 1\n",
    "\n",
    "Convolutional block dictionary:\n",
    "```python\n",
    "{\n",
    "    \"in_channels\": 16,\n",
    "    \"out_channels\": 32,\n",
    "    \"n_conv\": 2,\n",
    "    \"d_reduction\": \"MaxPooling\"\n",
    "}\n",
    "```\n",
    "(`network_normalization` is set to `InstanceNorm`)\n",
    "\n",
    "Corresponding architecture drawing:\n",
    "<br>\n",
    "<img src=\"../images/convBlock1.png\" width=\"700\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e3264",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Convolutional block - example 1\n",
    "\n",
    "Convolutional block dictionary:\n",
    "```python\n",
    "{\n",
    "    \"in_channels\": 32,\n",
    "    \"out_channels\": 64,\n",
    "    \"n_conv\": 3,\n",
    "    \"d_reduction\": \"stride\"\n",
    "}\n",
    "```\n",
    "(`network_normalization` is set to `BatchNorm`)\n",
    "\n",
    "Corresponding architecture drawing:\n",
    "<br>\n",
    "<img src=\"../images/convBlock2.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "A simple way to better visualize your random architecture is to construct it\n",
    "using `create_model` function from ClinicaDL. This function needs the list of\n",
    "options of the model stored in the JSON file as well as the size of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c931b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "\n",
    "from clinicadl.utils.maps_manager.maps_manager_utils import read_json\n",
    "from clinicadl.utils.caps_dataset.data import return_dataset, get_transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "def create_model(options, initial_shape):\n",
    "    \"\"\"\n",
    "    Creates model object from the model_name.\n",
    "    :param options: (Namespace) arguments needed to create the model.\n",
    "    :param initial_shape: (array-like) shape of the input data.\n",
    "    :return: (Module) the model object\n",
    "    \"\"\"\n",
    "    from clinicadl.utils.network.cnn.random import RandomArchitecture\n",
    "    if not hasattr(options, \"model\"):\n",
    "        model = RandomArchitecture(options.convolutions, options.n_fcblocks, initial_shape,\n",
    "                                   options.dropout, options.network_normalization, n_classes=2)\n",
    "    else:\n",
    "        try:\n",
    "            model = eval(options.model)(dropout=options.dropout)\n",
    "        except NameError:\n",
    "            raise NotImplementedError(\n",
    "                'The model wanted %s has not been implemented.' % options.model)\n",
    "\n",
    "    if options.gpu:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "\n",
    "    return model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read model options\n",
    "options = argparse.Namespace()\n",
    "model_options = read_json(options, json_path=\"random_search/test/commandline.json\")\n",
    "model_options.gpu = True\n",
    "\n",
    "# Find data input size\n",
    "_, transformations = get_transforms(mode, not model_options.unnormalize)\n",
    "dataset = return_dataset(mode, caps_dir, tsv_path,\n",
    "                         preprocessing_json, transformations, model_options)\n",
    "input_size = dataset.size\n",
    "\n",
    "# Create model and print summary\n",
    "model = create_model(model_options, input_size)\n",
    "summary(model, input_size)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
